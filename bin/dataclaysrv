#!/bin/bash
set -e
PREFIX="[dataclaysrv]"
function dataclayecho(){ echo "$PREFIX ${1}"; }
function dataclayerr(){ echo "!! $PREFIX ERROR: ${1}"; exit 1; }
function dataclaywarn(){ echo "$PREFIX WARNING: ${1}"; }
function dataclayinfo(){ echo "$PREFIX ${1}"; }

#=== FUNCTION ================================================================
# NAME: usage
# DESCRIPTION: Display usage information for this script.
# PARAMETER 1: ---
#=============================================================================
function create_globaljob_config {
	mkdir -p $DATACLAY_JOB_FOLDER
	# Global job config
	echo "######## Global environment variables ########" > $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_VERSION=$DATACLAY_VERSION" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_JOBID=$DATACLAY_JOBID" >> $GLOBAL_JOB_CONFIG
	echo "export LMNODE=$LMNODE" >> $GLOBAL_JOB_CONFIG
	echo "export CLIENTNODE=$CLIENTNODE" >> $GLOBAL_JOB_CONFIG
	echo "export DSNODES=\"$DSNODES\"" >> $GLOBAL_JOB_CONFIG
	echo "export PYTHON_EE_PER_NODE=$PYTHON_EE_PER_NODE" >> $GLOBAL_JOB_CONFIG
	echo "export JAVA_EE_PER_NODE=$JAVA_EE_PER_NODE" >> $GLOBAL_JOB_CONFIG	
	echo "export PROLOG_SCRIPT=$PROLOG_SCRIPT" >> $GLOBAL_JOB_CONFIG
	echo "export PROLOG_CMD=\"$PROLOG_CMD\"" >> $GLOBAL_JOB_CONFIG
	echo "export DEBUG=$DEBUG" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_USR=$DATACLAY_USR" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_PWD=$DATACLAY_PWD" >> $GLOBAL_JOB_CONFIG
	echo "export DATACLAY_DATASET=$DATACLAY_DATASET" >> $GLOBAL_JOB_CONFIG
}

function set_host_envs {
	JOB_CONFIG=$DATACLAY_JOB_FOLDER/${SERVICENAME}.config
	# Do not use DATACLAY_JOB_FOLDER since it is expanding current $HOME and not remote one
	JOB_FOLDER="\$HOME/.dataClay/$DATACLAY_JOBID/${SERVICENAME}"
	
	if [ $LMNODE == "localhost" ] || [ $LMNODE == "127.0.0.1" ]; then 
		LOGICMODULE_IP=127.0.0.1
	else 
		LOGICMODULE_IP=`host ${LMNODE} | rev | cut -d ' ' -f1 | rev`
	fi
	#CLIENT_IP=`host ${CLIENTNODE} | rev | cut -d ' ' -f1 | rev`
	STORAGE_PATH="$JOB_FOLDER/storage"
	APP_PATH="$JOB_FOLDER/app"
	APP_BIN_PATH="$APP_PATH/bin"
	MODEL_PATH="$JOB_FOLDER/model"
	MODEL_BIN_PATH="$MODEL_PATH/bin"
	STUBS_PATH="$APP_PATH/stubs"
	DEPLOY_PATH="$STORAGE_PATH/deploy_path/"
	DEPLOY_PATH_SRC="$DEPLOY_PATH/src"	
	DATACLAYCLIENTCONFIG="$JOB_FOLDER/cfgfiles/client.properties"
	DATACLAYGLOBALCONFIG="$JOB_FOLDER/cfgfiles/global.properties"
	DATACLAYSESSIONCONFIG="$JOB_FOLDER/cfgfiles/session.properties"
	JOB_ENV_FILE="$JOB_FOLDER/env.sh"
}

function create_job_config {
		
	# Host job config
	cat $GLOBAL_JOB_CONFIG > $JOB_CONFIG
	echo "######## $SERVICENAME environment variables ########" >> $JOB_CONFIG
	echo "export TRACING=$TRACING" >> $JOB_CONFIG
	echo "export JOB_FOLDER=$JOB_FOLDER" >> $JOB_CONFIG
	echo "export JOB_ENV_FILE=$JOB_ENV_FILE" >> $JOB_CONFIG	
	
	echo "export FLAGS=\"$FLAGS\"" >> $JOB_CONFIG
	echo "export SHUTDOWN_TIMEOUT=$SHUTDOWN_TIMEOUT" >> $JOB_CONFIG
	
	echo "export DATACLAYGLOBALCONFIG=$DATACLAYGLOBALCONFIG" >> $JOB_CONFIG
	echo "export DATACLAYCLIENTCONFIG=$DATACLAYCLIENTCONFIG" >> $JOB_CONFIG
	echo "export DATACLAYSESSIONCONFIG=$DATACLAYSESSIONCONFIG" >> $JOB_CONFIG
	echo "export APP_PATH=$APP_PATH" >> $JOB_CONFIG
	echo "export APP_BIN_PATH=$APP_BIN_PATH" >> $JOB_CONFIG
	
	echo "export MODEL_PATH=$MODEL_PATH" >> $JOB_CONFIG
	echo "export MODEL_BIN_PATH=$MODEL_BIN_PATH" >> $JOB_CONFIG
	
	echo "export STUBS_PATH=$STUBS_PATH" >> $JOB_CONFIG
	
	echo "export DATACLAY_JAR=$DATACLAY_JAR" >> $JOB_CONFIG
	echo "export DATACLAY_ENTRYPOINTS=$DATACLAY_ENTRYPOINTS" >> $JOB_CONFIG
	
	echo "export PATH=$PATH:\$PATH" >> $JOB_CONFIG
    echo "export PYTHONPATH=$PYTHONPATH:\$PYTHONPATH" >> $JOB_CONFIG
    echo "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:\$LD_LIBRARY_PATH" >> $JOB_CONFIG
    echo "export CLASSPATH=$CLASSPATH:\$CLASSPATH" >> $JOB_CONFIG
	

	echo "################" >> $JOB_CONFIG
	
}

function create_script { 
	SCRIPT_PATH=$1
	echo "#!/bin/bash" > $SCRIPT_PATH	
	echo "set -e" >> $SCRIPT_PATH
	cat $JOB_CONFIG >> $SCRIPT_PATH
	if [ ! -z "$PROLOG_SCRIPT" ]; then 
		cat $PROLOG_SCRIPT >> $SCRIPT_PATH
		printf "\n" >> $SCRIPT_PATH 
	fi
	if [ ! -z "$PROLOG_CMD" ]; then 
		echo $PROLOG_CMD >> $SCRIPT_PATH
	fi
}

function generate_env_file {
	# NOT ALL VARIABLES ARE USED (i.e. logicmodule port just for logicmodule image...)
	SERVICEIDX=$1
####	 Generic vars
	ENV_FILE=$JOB_FOLDER/env_"$SERVICEIDX".sh
	
	# PATH order: orchestration node path (for propagation), node path, dataclay path 
	# PYTHONPATH order: orchestration node pythonpath (for propagation), node pythonpath, dataclay pythonpath 
	# LD_LIBRARY_PATH order: same...
	echo "echo \"export PATH=\$PATH:$DATACLAY_PATH\" > $ENV_FILE" >> $START_SCRIPT
    echo "echo \"export PYTHONPATH=\$PYTHONPATH:$DATACLAY_PYTHONPATH\" >> $ENV_FILE" >> $START_SCRIPT
    echo "echo \"export LD_PRELOAD=$DATACLAY_LD_PRELOAD\" >> $ENV_FILE" >> $START_SCRIPT
    echo "echo \"export LD_LIBRARY_PATH=$DATACLAY_EXT_BIND:\$LD_LIBRARY_PATH:$DATACLAY_LD_LIBRARY_PATH\" >> $ENV_FILE" >> $START_SCRIPT
    echo "echo \"export CLASSPATH=\$CLASSPATH:$DATACLAY_CLASSPATH\" >> $ENV_FILE" >> $START_SCRIPT
    
    echo "echo \"export LOGICMODULE_PORT_TCP=1111\" >> $ENV_FILE " >> $START_SCRIPT
	echo "echo \"export DATACLAY_ADMIN_USER=admin\" >> $ENV_FILE" >> $START_SCRIPT
	echo "echo \"export DATACLAY_ADMIN_PASSWORD=admin\" >> $ENV_FILE" >> $START_SCRIPT
	echo "echo \"export DATACLAYGLOBALCONFIG=$DATACLAYGLOBALCONFIG\" >> $ENV_FILE" >> $START_SCRIPT
#	
####	 DSs	
	echo "echo \"export DEPLOY_PATH=$DEPLOY_PATH\" >> $ENV_FILE" >> $START_SCRIPT
	echo "echo \"export DEPLOY_PATH_SRC=$DEPLOY_PATH_SRC\" >> $ENV_FILE" >> $START_SCRIPT
	echo "echo \"export LOGICMODULE_HOST=$LOGICMODULE_IP\" >> $ENV_FILE" >> $START_SCRIPT
	echo "echo \"export DATASERVICE_NAME=$DATACLAY_HOST\" >> $ENV_FILE" >> $START_SCRIPT
	echo "echo \"export DATASERVICE_JAVA_PORT_TCP=$DS_PORT\" >> $ENV_FILE" >> $START_SCRIPT
	echo "echo \"export DATASERVICE_PYTHON_PORT_TCP=$DS_PORT\" >> $ENV_FILE" >> $START_SCRIPT
	#echo "echo \"export EXTRAE_CONFIG_FILE=/home/dataclayusr/extrae/extrae_python.xml\" >> $ENV_FILE" >> $START_SCRIPT
	DS_PORT=`expr $DS_PORT + 1`
}

function generate_global_properties { 
    echo "echo \"STORAGE_PATH=$STORAGE_PATH\" > $DATACLAYGLOBALCONFIG" >> $START_SCRIPT
    echo "echo \"STATE_FILE_PATH=$STORAGE_PATH/state.txt\" >> $DATACLAYGLOBALCONFIG" >> $START_SCRIPT
    echo "echo \"EE_PERSISTENT_INFO_PATH=$STORAGE_PATH/\" >> $DATACLAYGLOBALCONFIG" >> $START_SCRIPT
    echo "echo \"DEFAULT_GLOBALGC_CACHE_PATH=$STORAGE_PATH/\" >> $DATACLAYGLOBALCONFIG" >> $START_SCRIPT
	if [ ! -z "$GLOBAL_PROPS" ] ; then
		while IFS= read -r line
		do
			dataclaywarn "Found global properties configuration: $line"
    		echo "echo \"$line\" >> $DATACLAYGLOBALCONFIG" >> $START_SCRIPT
		done < "$GLOBAL_PROPS"
	fi
	if [ "$DEBUG" == True ]; then 
   		echo "echo \"CHECK_LOG4J_DEBUG=true\" >> $DATACLAYGLOBALCONFIG" >> $START_SCRIPT
	fi 
}

function generate_client_properties { 
    echo "echo \"HOST=$LOGICMODULE_IP\" > $DATACLAYCLIENTCONFIG" >> $START_SCRIPT
    echo "echo \"TCPPORT=1111\" >> $DATACLAYCLIENTCONFIG" >> $START_SCRIPT
}

function generate_session_properties { 

    echo "echo \"DataClayClientConfig=$DATACLAYCLIENTCONFIG\" > $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
    echo "echo \"Account=$DATACLAY_USR\" >> $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
    echo "echo \"Password=$DATACLAY_PWD\" >> $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
    echo "echo \"StubsClasspath=$STUBS_PATH\" >> $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
    echo "echo \"DataSetForStore=$DATACLAY_DATASET\" >> $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
    echo "echo \"DataSets=$DATACLAY_DATASET\" >> $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
    #echo "echo \"DataClayGlobalConfig=$DATACLAYGLOBALCONFIG\" >> $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
	if [ "$TRACING" = true ] ; then
    	echo "echo \"Tracing=True\" >> $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
		#IFS=', ' read -r -a HOSTS_ARRAY <<< "$HOSTS"
    	#echo "echo \"ExtraeStartingTaskID=${#HOSTS_ARRAY[@]}\" >> $DATACLAYSESSIONCONFIG" >> $START_SCRIPT
	fi
}

function link_singularity {
	#### create link to singularity images for using it in frontend (or for backends without internet access and shared FS)
	IMAGE=$1
	SINGULARITY_JOB_FOLDER=$DATACLAY_JOB_FOLDER/$SERVICENAME/images
	mkdir -p $SINGULARITY_JOB_FOLDER
	touch $SINGULARITY_JOB_FOLDER/Singularity
	ln -s $SINGULARITY_IMAGES_HOME/$IMAGE  $SINGULARITY_JOB_FOLDER/$IMAGE
}

# ===================== DEPLOYMENT SCRIPTS ======================================= #

function deploy { 
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name (logicmodule, dsjava1_1, dspython1_2, client, ...)
	SERVICE=$4 #service (logicmodule, dsjava, dspython, client) 
	
	dataclayecho "Deploying $SERVICENAME to $HOSTNAME..."
	set_host_envs
	create_job_config
		
	DEPLOY_SCRIPT=$(mktemp /tmp/${DATACLAY_JOBID}_${SERVICENAME}_deploy.XXXX)
	create_script $DEPLOY_SCRIPT 	
	
	# link to singularity images in frontend (for shared fs)
	link_singularity ${SERVICE}.sif	
	
	####### DEPLOY SCRIPT ####### 
	# prepare paths
	echo "mkdir -p $JOB_FOLDER" >> $DEPLOY_SCRIPT
	echo "mkdir -p $JOB_FOLDER/cfgfiles" >> $DEPLOY_SCRIPT
	echo "mkdir -p $DEPLOY_PATH" >> $DEPLOY_SCRIPT
	echo "mkdir -p $DEPLOY_PATH_SRC" >> $DEPLOY_SCRIPT
	echo "mkdir -p $STORAGE_PATH" >> $DEPLOY_SCRIPT
	echo "rm -rf \$HOME/.singularity/instances/logs" >> $DEPLOY_SCRIPT
	echo "if [ ! -f $JOB_FOLDER/images/Singularity ]; then touch $JOB_FOLDER/images/Singularity; fi" >> $DEPLOY_SCRIPT
	echo "if [ ! -f $JOB_FOLDER/images/${SERVICE}.sif ]; then
		singularity pull $JOB_FOLDER/images/${SERVICE}.sif library://support-dataclay/default/${SERVICE}:$DATACLAY_VERSION;
	fi" >> $DEPLOY_SCRIPT
	
	# Deploy 
	ssh "${HOSTNAME}" "bash -s" < $DEPLOY_SCRIPT
	
	# Send log4j configuration
	scp -q $LOG4J_CONFIG $HOSTNAME:$JOB_FOLDER/cfgfiles/log4j2.xml
	# Send script
	chmod +x $DEPLOY_SCRIPT
	scp -q $DEPLOY_SCRIPT $HOSTNAME:$JOB_FOLDER/deploy
	
	# Clean temporary scripts
	rm $DEPLOY_SCRIPT
	
	dataclayecho "${SERVICENAME} deployed to $HOSTNAME"
}


# ===================== START SCRIPTS ======================================= #

function start { 
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name
	SERVICE=$4 #service (logicmodule, dsjava, dspython, client) 
	
	set_host_envs
	create_job_config

	START_SCRIPT=$(mktemp /tmp/${DATACLAY_JOBID}_${SERVICENAME}_start.XXXX) # i.e. 24000_LM
	create_script $START_SCRIPT 
	
	# generate global properties 
	generate_global_properties
	
	generate_env_file $SERVICENAME
	
	#### TODO: specialize this
	if [ $SERVICE != "client" ]; then 
		echo "cd $JOB_FOLDER" >> $START_SCRIPT
		echo "echo \"Starting ${SERVICENAME}\"" >> $START_SCRIPT

		if [ ! -z $EXTRAE_CONFIG_FILE ]; then 
			# extrae config file is defined 
			EXTRAE_CONFIG_MOUNT="-B $EXTRAE_CONFIG_FILE:/home/dataclayusr/extrae/extrae_basic.xml"
		fi
		DATACLAY_BIND=""
		if [ ! -z "$DATACLAY_EXT_BIND" ]; then 
			IFS=':' read -r -a DATACLAY_BIND_ARR <<< "$DATACLAY_EXT_BIND"
			for MOUNT_POINT in "${DATACLAY_BIND_ARR[@]}"; do
				DATACLAY_BIND="$DATACLAY_BIND -B $MOUNT_POINT:$MOUNT_POINT"
			done
		fi
		# $EXTRAE_CONFIG_MOUNT -B $USR_LIB:/usr/lib64/ \
		echo "singularity instance start -B $JOB_FOLDER/cfgfiles/log4j2.xml:/home/dataclayusr/dataclay/logging/log4j2.xml \
		$DATACLAY_BIND -B $JOB_FOLDER/env_$SERVICENAME.sh:/.singularity.d/env/env.sh \
		$JOB_FOLDER/images/${SERVICE}.sif ${SERVICENAME} $FLAGS" >> $START_SCRIPT

	else 
		if [ ! -f $DATACLAY_JOB_FOLDER/client.config ]; then 
			# in case client is named differently
			ln -s $JOB_CONFIG $DATACLAY_JOB_FOLDER/client.config
		fi
		echo "mkdir -p $APP_PATH" >> $START_SCRIPT
		echo "mkdir -p $APP_BIN_PATH" >> $START_SCRIPT
		echo "mkdir -p $STUBS_PATH" >> $START_SCRIPT
		echo "mkdir -p $MODEL_PATH" >> $START_SCRIPT
		echo "mkdir -p $MODEL_BIN_PATH" >> $START_SCRIPT
		# Generate client properties 
		generate_client_properties
		# Generate session.properties. If --tracing was provided, add session.properties field. 
		generate_session_properties
	fi
	
	# Send scripts
	echo "mkdir -p $JOB_FOLDER" | ssh "${HOSTNAME}" bash -s #sanity check
	chmod +x $START_SCRIPT
	scp -q $START_SCRIPT $HOSTNAME:$JOB_FOLDER/start
	
	# Start 
	echo "$JOB_FOLDER/start" | ssh "${HOSTNAME}" bash -s
	
	# Clean temporary scripts
	rm $START_SCRIPT

}


function deploy_client {
	#### SPECIFIC DEPLOYMENT FOR CLIENT NODES #### 
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name (logicmodule, dsjava1_1, dspython1_2, client, ...)
	
	set_host_envs
	create_job_config
	
	CLIENT_SCRIPT=$(mktemp /tmp/${DATACLAY_JOBID}_${SERVICENAME}_client.XXXX)	
	create_script $CLIENT_SCRIPT 		
	create_job_config
	
	####### CLIENT SCRIPT ####### 
	echo "cd $APP_PATH"  >> $CLIENT_SCRIPT
	
	if [ ! -z $EXTRAE_CONFIG_FILE ]; then 
		# extrae config file is defined 
		EXTRAE_CONFIG_MOUNT="-B $EXTRAE_CONFIG_FILE:/home/dataclayusr/extrae/extrae_basic.xml"
	fi
	DATACLAY_BIND=""
	if [ ! -z "$DATACLAY_EXT_BIND" ]; then 
		IFS=':' read -r -a DATACLAY_BIND_ARR <<< "$DATACLAY_EXT_BIND"
		for MOUNT_POINT in "${DATACLAY_BIND_ARR[@]}"; do
			DATACLAY_BIND="$DATACLAY_BIND -B $MOUNT_POINT:$MOUNT_POINT"
		done
	fi
		# -B /etc/localtime:/etc/localtime \
		# $EXTRAE_CONFIG_MOUNT -B $USR_LIB:/usr/lib64/ \
		
	echo "singularity \$1 -B $JOB_FOLDER/cfgfiles/log4j2.xml:/home/dataclayusr/dataclay/logging/log4j2.xml \
		$DATACLAY_BIND -B $JOB_FOLDER/env_$SERVICENAME.sh:/.singularity.d/env/env.sh \
		$JOB_FOLDER/images/client.sif \${@:2}" >> $CLIENT_SCRIPT
	
	# Send scripts
	echo "mkdir -p $JOB_FOLDER" | ssh "${HOSTNAME}" bash -s #sanity check
	chmod +x $CLIENT_SCRIPT
	scp -q $CLIENT_SCRIPT $HOSTNAME:$JOB_FOLDER/client
		
	rm $CLIENT_SCRIPT
}

# ===================== STOP SCRIPTS ======================================= #
function stop { 
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name (logicmodule, dsjava1_1, dspython1_2, client, ...)
	SERVICE=$4 #service (logicmodule, dsjava, dspython, client) 
	
	set_host_envs
	create_job_config
	
	dataclayecho "Stopping ${SERVICENAME} at $HOSTNAME"
	STOP_SCRIPT=$(mktemp /tmp/${DATACLAY_JOBID}_${SERVICENAME}_stop.XXXX)
	create_script $STOP_SCRIPT
	
	SIGNAL="SIGTERM"
	if [ $SERVICE == "dspython" ]; then 
		SIGNAL="SIGINT"
	fi 
	echo "if singularity instance list | grep $SERVICENAME; then" >>  $STOP_SCRIPT
	echo "singularity instance stop -s $SIGNAL -t $SHUTDOWN_TIMEOUT $SERVICENAME" >> $STOP_SCRIPT
	echo "fi" >> $STOP_SCRIPT

	# Send scripts
	echo "mkdir -p $JOB_FOLDER" | ssh "${HOSTNAME}" bash -s #sanity check
	chmod +x $STOP_SCRIPT
	scp -q $STOP_SCRIPT $HOSTNAME:$JOB_FOLDER/stop
	
	# Deploy 
	echo "$JOB_FOLDER/stop" | ssh "${HOSTNAME}" bash -s
	
	# Clean temporary scripts
	rm $STOP_SCRIPT
}

function clean { 
	HOSTNAME=$1
	DATACLAY_HOST=$2 #dataclay host name (logicmodule, DS1, DS2, ...)
	SERVICENAME=$3 #service name (logicmodule, dsjava1_1, dspython1_2, client, ...)
	set_host_envs
	echo "rm -rf $JOB_FOLDER" | ssh "${HOSTNAME}" bash -s
}

# ==================== SERVICES ============================ #

function dataclaydeploy { 
	
	dataclayclean

  	dataclaywarn "Job was not deployed. Going to deploy."
	dataclayinfo "========== Deploying dataClay =========="

	dataclayecho "- deploying to hosts = \"$HOSTS\""
	HOSTS=($(echo $HOSTS | tr " " "\n"))
	if [ "${#HOSTS[@]}" -lt 3 ]; then
		dataclayerr "Minimum 3 hosts must be provided (logic module, a data service node and a client node)"
	fi
	CLIENTNODE=${HOSTS[0]} #1st node for client 
	LMNODE=${HOSTS[1]}     #2nd node for LM
	DSNODES=${HOSTS[@]:2}  # DS nodes

	# Check if Singularity images exist 
	if [ ! -d "$SINGULARITY_IMAGES_HOME" ]; then 
		dataclaywarn "Singularity images not found at $SINGULARITY_IMAGES_HOME. Make sure installation was correct."
		exit 1
	fi
	create_globaljob_config

	deploy $LMNODE ${LM_HOSTID} logicmodule logicmodule 
	i=1
	for NODE in $DSNODES; do
		for j in $(seq 1 $JAVA_EE_PER_NODE); do
			SERVICENAME=dsjava${i}_${j}
			deploy $NODE ${DSNAME_PREFIX}${i} $SERVICENAME dsjava
		done 
		for j in $(seq 1 $PYTHON_EE_PER_NODE); do
			SERVICENAME=dspython${i}_${j}
			deploy $NODE ${DSNAME_PREFIX}${i} $SERVICENAME dspython
		done
		i=$(($i + 1))
	done
	deploy $CLIENTNODE ${CLIENT_HOSTID} client client
	deploy_client $CLIENTNODE ${CLIENT_HOSTID} client
	
	echo "$DATACLAY_JOBID" >> $DEPLOYED_DATACLAY_JOBS
	dataclayinfo "========== dataClay deployed! =========="
}

function dataclaystart { 

	if [ "$DEPLOYED" == false ]; then 
		dataclaydeploy
	else 
		dataclayinfo "INFO: Already deployed dataClay found."
	fi

	dataclayinfo "========== Starting dataClay ========== "

	# Get client config to get DS nodes and LM node
	source $GLOBAL_JOB_CONFIG
	start $LMNODE ${LM_HOSTID} logicmodule logicmodule
	i=1
	for NODE in $DSNODES; do
		for j in $(seq 1 $JAVA_EE_PER_NODE); do
			SERVICENAME=dsjava${i}_${j}
			start $NODE ${DSNAME_PREFIX}${i} $SERVICENAME dsjava
		done 
		for j in $(seq 1 $PYTHON_EE_PER_NODE); do
			SERVICENAME=dspython${i}_${j}
			start $NODE ${DSNAME_PREFIX}${i} $SERVICENAME dspython 
		done
		i=$(($i + 1))
	done
	start $CLIENTNODE ${CLIENT_HOSTID} client client
	
	############ VERIFY ############ 
	# Wait for dataClay to be read
	$SCRIPTDIR/dataclay WaitForDataClayToBeAlive 20 3
	
	# Wait for backends 
	for DSNODE in $DSNODES; do
	   DSCOUNTER=0
	   dataclayecho "Waiting for $DSNODE Java execution environments to be ready... "
	   while [ $DSCOUNTER -ne $JAVA_EE_PER_NODE ]; do
	       DSCOUNTER=`$SCRIPTDIR/dataclay GetBackends admin admin java | grep "${DSNAME_PREFIX}" | wc -l`
	   done
	   dataclayecho "$DSNODE Java execution environments are ready"
	
	   DSCOUNTER=0
	   dataclayecho "Waiting for $DSNODE Python execution environments to be ready... "
	   while [ $DSCOUNTER -ne $PYTHON_EE_PER_NODE ]; do
	       DSCOUNTER=`$SCRIPTDIR/dataclay GetBackends admin admin python | grep "${DSNAME_PREFIX}" | wc -l`
	   done
	   dataclayecho "$DSNODE Python execution environments are ready"
	done
	
	dataclayinfo "========== dataClay started! ========== "
}

function dataclaystop { 
	
	dataclayinfo "========== Stopping dataClay ========== "

	# ------------------------------ dataClay Job configuration -------------------------------------------
	# Get client config to get DS nodes and LM node
	GLOBAL_JOB_CONFIG="$HOME/.dataClay/$DATACLAY_JOBID/job.config"
	source $GLOBAL_JOB_CONFIG
	#------------------------------------------------------------------------------------------------------
	i=1
	for NODE in $DSNODES; do
		#### NOTE: stop first dspython
		for j in $(seq 1 $PYTHON_EE_PER_NODE); do
			SERVICENAME=dspython${i}_${j}
			stop $NODE ${DSNAME_PREFIX}${i} $SERVICENAME dspython
		done
		for j in $(seq 1 $JAVA_EE_PER_NODE); do
			SERVICENAME=dsjava${i}_${j}
			stop $NODE ${DSNAME_PREFIX}${i} $SERVICENAME dsjava
		done 
		i=$(($i + 1))
	done
	stop $LMNODE ${LM_HOSTID} logicmodule logicmodule
	
	dataclayinfo "========== dataClay stopped! ========== "
}


function dataclayclean { 
	dataclayinfo "========== Cleaning dataClay ========== "

	# remove from deployed.jobs
	sed -i "/${DATACLAY_JOBID}$/d" $DEPLOYED_DATACLAY_JOBS
	# replace from job pids 
	sed -i "/${DATACLAY_JOBID}$/d" $DATACLAY_JOB_PIDS
	echo "$PPID=$DATACLAY_JOBID" >> $DATACLAY_JOB_PIDS
		
	if [ -d $DATACLAY_JOB_FOLDER ]; then
		CLEAN=true
		dataclaystop
		i=1
		for NODE in $DSNODES; do
			for j in $(seq 1 $PYTHON_EE_PER_NODE); do
				SERVICENAME=dspython${i}_${j}
				clean $NODE ${DSNAME_PREFIX}${i} $SERVICENAME dspython
			done
			for j in $(seq 1 $JAVA_EE_PER_NODE); do
				SERVICENAME=dsjava${i}_${j}
				clean $NODE ${DSNAME_PREFIX}${i} $SERVICENAME dsjava
			done 
			i=$(($i + 1))
		done
		clean $LMNODE ${LM_HOSTID} logicmodule logicmodule
		clean $CLIENTNODE ${CLIENT_HOSTID} client client
		rm -rf $DATACLAY_JOB_FOLDER
	fi
		
	# stop all remaining instances in current node (for localhost) 
	# if singularity is installed locally: 
	if hash singularity 2>/dev/null; then
		if [[ $(singularity instance list | wc -l) -gt 1 ]]; then 
			singularity instance stop -a	
		fi
	fi
	
	dataclayinfo "========== dataClay cleaned! ========== "
	
}

# ==================== MAIN ============================ #

if [ "$#" -lt 1 ]; then
	dataclayerr "Please provide argument to start or stop dataClay" 
fi
START=false
STOP=false
RESTART=false
if [ "$1" == "start" ]; then 
	START=true 
elif [ "$1" == "stop" ]; then 
	STOP=true
elif [ "$1" == "restart" ]; then 
	RESTART=true 
else
	dataclayerr "First argument must be start or stop"
fi 
# Check DATACLAY_BASE is set 
SCRIPTDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
DATACLAY_BASE=$SCRIPTDIR/..
#if [ -z $DATACLAY_BASE ]; then
#        dataclayerr "Please set DATACLAY_BASE in your host (via bashrc, ...)!"
#fi 
if [ ! -d $HOME/.dataClay ]; then
	dataclaywarn "Creating $HOME/.dataClay folder." 
	mkdir $HOME/.dataClay 
fi
DATACLAY_VERSION=$(cat $DATACLAY_BASE/VERSION.txt)
DATACLAY_JOB_PIDS=$HOME/.dataClay/job.pids
DEPLOYED_DATACLAY_JOBS=$HOME/.dataClay/deployed.jobs

### PREPARE ###
if [ ! -f $DATACLAY_JOB_PIDS ]; then touch $DATACLAY_JOB_PIDS; fi
if [ ! -f $DEPLOYED_DATACLAY_JOBS ]; then touch $DEPLOYED_DATACLAY_JOBS; fi

if [ ! -z $SLURM_JOBID ]; then 
	export DATACLAY_JOBID=$SLURM_JOBID
    dataclaywarn "SLURM JOB ID detected. Using it. DATACLAY_JOBID = $DATACLAY_JOBID"
fi

if [ -z $DATACLAY_JOBID ]; then
	ID=$($SCRIPTDIR/dataclayid $PPID)
	# if ID exists, set it 
	if [ ! -z $ID ]; then
		export DATACLAY_JOBID=$ID
    	dataclaywarn "Found current process $PPID using DATACLAY_JOBID"
	fi
fi 

# Check DATACLAY_JOBID is set 
if [ -z $DATACLAY_JOBID ]; then
	if [[ $(ls -l $HOME/.dataClay | grep "^d") ]]; then 
		LAST_JOB=$(basename $(ls -td -- $HOME/.dataClay/*/ | head -n 1))
	fi
	if [ -z "$LAST_JOB" ]; then
		NUMERIC_VERSION=${DATACLAY_VERSION%.dev}
		export DATACLAY_JOBID=$((${NUMERIC_VERSION//.} * 1000))
	else 
		export DATACLAY_JOBID=$(($LAST_JOB + 1))
	fi
    dataclaywarn "DATACLAY_JOBID environment not set. Generating one = $DATACLAY_JOBID"
else 
    dataclayinfo "Found DATACLAY_JOBID = $DATACLAY_JOBID"
fi

if [ -z $ID ]; then 
	# add parent pid to job pids of dataClay 
	echo "$PPID=$DATACLAY_JOBID" >> $DATACLAY_JOB_PIDS
fi
if [ -z $DATACLAY_JOBID ]; then
        dataclayerr "CRITICAL: please set DATACLAY_JOBID!"
fi
DEPLOYED=false
while IFS= read -r line; do
  if [ "$line" == "$DATACLAY_JOBID" ]; then
  	 DEPLOYED=true
  fi
done < "$DEPLOYED_DATACLAY_JOBS"

##### process arguments #####
shift

# global vars
DATACLAY_JOB_FOLDER="$HOME/.dataClay/$DATACLAY_JOBID"
GLOBAL_JOB_CONFIG=$DATACLAY_JOB_FOLDER/job.config
CLIENT_HOSTID="client"
LM_HOSTID="logicmodule"
DSNAME_PREFIX="dataservice"
DATACLAY_USR=bsc_user
DATACLAY_PWD=bsc_user
DATACLAY_DATASET=bsc_dataset
PYTHON_VERSION=3.7
if [ -d "/usr/lib64" ]; then 
	USR_LIB="/usr/lib64/"
else 
	USR_LIB="/usr/lib/"
fi
DATACLAY_PATH="${DATACLAY_BASE}/bin"
JAVA_EE_PER_NODE=1
PYTHON_EE_PER_NODE=1
DS_PORT=2222
SINGULARITY_IMAGES_HOME=$DATACLAY_BASE/singularity/images/
LOG4J_CONFIG=$DATACLAY_BASE/logging/info.xml
DEBUG=False
HOSTS="localhost localhost localhost" 

#### DATACLAY ENV. VARIABLES THAT MIGHT BE AFFECTED BY HOST ENVIRONMENT #####
### WARNING: THESE VARIABLES ARE DEFINED IN DOCKERFILES 
DATACLAY_JAR="/home/dataclayusr/dataclay/dataclay.jar"
DATACLAY_ENTRYPOINTS="/home/dataclayusr/dataclay/entrypoints"
DATACLAY_VIRTUALENV="/home/dataclayusr/dataclay/dataclay_venv"
DATACLAY_EXTRAE_HOME="/home/dataclayusr/.extrae/"
DATACLAY_PATH="${DATACLAY_VIRTUALENV}/bin:${DATACLAY_ENTRYPOINTS}:${DATACLAY_EXTRAE_HOME}/bin"
DATACLAY_PYTHONPATH="${DATACLAY_EXTRAE_HOME}/libexec:${DATACLAY_EXTRAE_HOME}/lib:${DATACLAY_VIRTUALENV}/lib/python${PYTHON_VERSION}/site-packages"
DATACLAY_LD_LIBRARY_PATH="${DATACLAY_EXTRAE_HOME}/lib"
DATACLAY_LD_PRELOAD="${DATACLAY_EXTRAE_HOME}/lib/libpttrace.so"
DATACLAY_CLASSPATH="${DATACLAY_JAR}"
###############################################################

# Start args
TRACING=false
FLAGS=""
GLOBAL_PROPS=""

# Stop args
SHUTDOWN_TIMEOUT=300

# Args
while test $# -gt 0
do
	case "$1" in
			--python-ee-per-node) 
		    	shift 
		    	PYTHON_EE_PER_NODE=$1
	            dataclayecho "- setting python execution environment per node = $PYTHON_EE_PER_NODE"
		    	;;
			--hosts)
		   		shift
		    	HOSTS=$1
	            ;;
	        --prolog-cmd) 
	        	shift
	        	PROLOG_CMD=$1
	            dataclayecho "- setting prolog command = $PROLOG_CMD"
	        	;;
	        --prolog-script) 
	        	shift
	        	PROLOG_SCRIPT=$1
	            dataclayecho "- setting prolog script = $PROLOG_SCRIPT"
	        	;;
	        --globalprops) 
	        	shift 
	        	GLOBAL_PROPS=$1 
	            dataclayecho "- deploying global properties at $GLOBAL_PROPS"
	        	;;
	        --cleandeploy) 
	        	DEPLOYED=false
	            dataclaywarn "Clean deploy option provided."
	        	;;
	        --debug) 
	            FLAGS="$FLAGS $1"
	            LOG4J_CONFIG=$DATACLAY_BASE/logging/debug.xml
	            DEBUG=True
	            dataclayecho "- debug mode: enabled "
	            ;; 
	        --tracing)
		    	TRACING=true
	            FLAGS="$FLAGS $1" 
	            dataclayecho "- tracing mode: enabled "
	            ;;
			--shutdown-timeout)
		    	shift
		    	SHUTDOWN_TIMEOUT=$1
		    	dataclayecho "- shutdown timeout = $SHUTDOWN_TIMEOUT"
	            ;;
			--*) 
				dataclayerr "Wrong option $1 provided" 
				;;
			*)  
				dataclayerr "Wrong argument $1 provided"
            ;;
    esac
    shift
done

if [ ! -f $PROLOG_SCRIPT ]; then 
	dataclayerr "Prolog $PROLOG_SCRIPT not found."
fi

if [ "$START" == true ]; then 
	dataclaystart
elif  [ "$STOP" == true ]; then 
	dataclaystop 
elif  [ "$RESTART" == true ]; then 
	dataclaystop
	dataclaystart
fi 