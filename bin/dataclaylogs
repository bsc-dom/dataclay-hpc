#!/bin/bash
function get_logs { 
	HOSTNAME=$1
	LOG_DIR=${HOME}/.dataClay/${DATACLAY_JOBID}
	scp -r $HOSTNAME:$LOG_DIR/logs $LOG_DIR
} 
if [ "$#" -ne 1 ] && [ "$#" -ne 2 ] ; then
	echo "ERROR: usage: $0 <jobid> <optional:pattern> "
	echo "	 pattern: if not provided * is set as pattern, logicmodule, dspython*, dsjava_localhost, dsjava*, ds* (grep style pattern)"
	exit 1
fi
DATACLAY_JOBID=$1
if [ ! -d  $HOME/.dataClay/$DATACLAY_JOBID/ ]; then 
	echo "ERROR: Logs for job with ID = $DATACLAY_JOBID not found."
	exit 1
fi 
PATTERN="*"
if [ "$#" -gt 1 ]; then
	PATTERN=$2
fi
# ------------------------------ dataClay Job configuration -------------------------------------------
JOB_CONFIG="$HOME/.dataClay/$DATACLAY_JOBID/job.config"
source $JOB_CONFIG
#------------------------------------------------------------------------------------------------------

# for each host in the job, get it and store in folder 
echo "Getting new logs into $HOME/.dataClay/$DATACLAY_JOBID/logs ..."
pushd $HOME/.dataClay/$DATACLAY_JOBID/ >/dev/null
get_logs $LMNODE
for NODE in $DSNODES; do
	get_logs $NODE 
done
get_logs $CLIENTNODE
popd >/dev/null

LOGS_DIR=${HOME}/.dataClay/${DATACLAY_JOBID}/logs
pushd $LOGS_DIR >/dev/null
echo "================ LOGS ================"
grep --color=always "" ${PATTERN}* 2>/dev/null
popd >/dev/null